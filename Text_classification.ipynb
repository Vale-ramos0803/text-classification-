{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#text classification dataset"
      ],
      "metadata": {
        "id": "I22Q0OXtx_u5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLhTcj73xnMi",
        "outputId": "ccfea1a3-2b1a-4ff5-e9c5-874ab3fa12e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "\u001b[1m2110848/2110848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.3325 - loss: 3.1983 - val_accuracy: 0.6149 - val_loss: 1.9524\n",
            "Epoch 2/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.6514 - loss: 1.7352 - val_accuracy: 0.6244 - val_loss: 1.5130\n",
            "Epoch 3/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7146 - loss: 1.2691 - val_accuracy: 0.7145 - val_loss: 1.2959\n",
            "Epoch 4/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7637 - loss: 1.0717 - val_accuracy: 0.7101 - val_loss: 1.2128\n",
            "Epoch 5/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.7998 - loss: 0.9023 - val_accuracy: 0.7412 - val_loss: 1.1094\n",
            "Epoch 6/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.8361 - loss: 0.7612 - val_accuracy: 0.7813 - val_loss: 1.0233\n",
            "Epoch 7/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8674 - loss: 0.6210 - val_accuracy: 0.7791 - val_loss: 0.9880\n",
            "Epoch 8/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8879 - loss: 0.5481 - val_accuracy: 0.7852 - val_loss: 0.9611\n",
            "Epoch 9/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9053 - loss: 0.4534 - val_accuracy: 0.7958 - val_loss: 0.9195\n",
            "Epoch 10/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9180 - loss: 0.3955 - val_accuracy: 0.8036 - val_loss: 0.8980\n",
            "Epoch 11/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9331 - loss: 0.3390 - val_accuracy: 0.7947 - val_loss: 0.9360\n",
            "Epoch 12/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9336 - loss: 0.3024 - val_accuracy: 0.8052 - val_loss: 0.8896\n",
            "Epoch 13/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9426 - loss: 0.2579 - val_accuracy: 0.8058 - val_loss: 0.8970\n",
            "Epoch 14/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9473 - loss: 0.2336 - val_accuracy: 0.8075 - val_loss: 0.9077\n",
            "Epoch 15/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9543 - loss: 0.1956 - val_accuracy: 0.7880 - val_loss: 0.9606\n",
            "Epoch 16/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9592 - loss: 0.1712 - val_accuracy: 0.7963 - val_loss: 0.9269\n",
            "Epoch 17/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9592 - loss: 0.1672 - val_accuracy: 0.7896 - val_loss: 0.9666\n",
            "Epoch 18/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9620 - loss: 0.1570 - val_accuracy: 0.8019 - val_loss: 0.9197\n",
            "Epoch 19/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9614 - loss: 0.1442 - val_accuracy: 0.8052 - val_loss: 0.9649\n",
            "Epoch 20/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9595 - loss: 0.1380 - val_accuracy: 0.7807 - val_loss: 1.1269\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras import models, layers\n",
        "import numpy as np\n",
        "\n",
        "# 1. Carga el dataset Reuters (clasifica noticias en 46 categorías)\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "# 2. Vectorización one-hot de las secuencias\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, seq in enumerate(sequences):\n",
        "        results[i, seq] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test  = vectorize_sequences(test_data)\n",
        "\n",
        "# 3. One-hot de las etiquetas\n",
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, lab in enumerate(labels):\n",
        "        results[i, lab] = 1.\n",
        "    return results\n",
        "\n",
        "y_train = to_one_hot(train_labels)\n",
        "y_test  = to_one_hot(test_labels)\n",
        "\n",
        "# 4. Construye un modelo simple de clasificación\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(10000,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(46, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 5. Entrena\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 1. Evalúa loss y accuracy en el conjunto de prueba\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=512, verbose=1)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# 2. Obtén las predicciones (clase con mayor probabilidad)\n",
        "y_prob = model.predict(x_test, batch_size=512, verbose=1)   # shape (num_samples, 46)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# 3. Reporte de precisión, recall y F1-score por categoría\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVuec6x5yIHV",
        "outputId": "e4402c07-bd57-4ae9-c203-a2906df70af4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7728 - loss: 1.1139\n",
            "Test loss: 1.1548\n",
            "Test accuracy: 0.7676\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9000    0.7500    0.8182        12\n",
            "           1     0.6538    0.8095    0.7234       105\n",
            "           2     0.7143    0.5000    0.5882        20\n",
            "           3     0.9322    0.9139    0.9230       813\n",
            "           4     0.7253    0.9135    0.8086       474\n",
            "           5     0.0000    0.0000    0.0000         5\n",
            "           6     0.8182    0.6429    0.7200        14\n",
            "           7     1.0000    0.3333    0.5000         3\n",
            "           8     0.7917    0.5000    0.6129        38\n",
            "           9     0.8500    0.6800    0.7556        25\n",
            "          10     0.9200    0.7667    0.8364        30\n",
            "          11     0.7143    0.6627    0.6875        83\n",
            "          12     1.0000    0.1538    0.2667        13\n",
            "          13     0.6154    0.6486    0.6316        37\n",
            "          14     0.0000    0.0000    0.0000         2\n",
            "          15     0.5000    0.1111    0.1818         9\n",
            "          16     0.7528    0.6768    0.7128        99\n",
            "          17     0.8000    0.3333    0.4706        12\n",
            "          18     0.8000    0.6000    0.6857        20\n",
            "          19     0.4675    0.8647    0.6069       133\n",
            "          20     0.8667    0.1857    0.3059        70\n",
            "          21     0.7619    0.5926    0.6667        27\n",
            "          22     0.0000    0.0000    0.0000         7\n",
            "          23     0.6000    0.2500    0.3529        12\n",
            "          24     0.5385    0.3684    0.4375        19\n",
            "          25     0.8125    0.4194    0.5532        31\n",
            "          26     1.0000    0.1250    0.2222         8\n",
            "          27     1.0000    0.2500    0.4000         4\n",
            "          28     0.2222    0.2000    0.2105        10\n",
            "          29     0.4000    0.5000    0.4444         4\n",
            "          30     0.6667    0.3333    0.4444        12\n",
            "          31     0.8000    0.3077    0.4444        13\n",
            "          32     0.6364    0.7000    0.6667        10\n",
            "          33     1.0000    0.8000    0.8889         5\n",
            "          34     1.0000    0.1429    0.2500         7\n",
            "          35     1.0000    0.1667    0.2857         6\n",
            "          36     0.4545    0.4545    0.4545        11\n",
            "          37     0.0000    0.0000    0.0000         2\n",
            "          38     0.0000    0.0000    0.0000         3\n",
            "          39     0.0000    0.0000    0.0000         5\n",
            "          40     0.0000    0.0000    0.0000        10\n",
            "          41     0.5000    0.1250    0.2000         8\n",
            "          42     0.0000    0.0000    0.0000         3\n",
            "          43     0.8333    0.8333    0.8333         6\n",
            "          44     1.0000    0.8000    0.8889         5\n",
            "          45     1.0000    1.0000    1.0000         1\n",
            "\n",
            "    accuracy                         0.7676      2246\n",
            "   macro avg     0.6315    0.4221    0.4670      2246\n",
            "weighted avg     0.7806    0.7676    0.7504      2246\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supongamos que este es tu modelo ya entrenado\n",
        "model.save(\"Text_classification.h5\")"
      ],
      "metadata": {
        "id": "uTM1KX-O2Bsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73bd90c4-42c8-4463-f09f-6f531bc95c72"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"Text_classification.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VBzRbF6a1NcH",
        "outputId": "8bf315c0-0413-4438-bc58-4d46310b896e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2dae170c-7a90-4c7e-8a82-f5504b54e9a1\", \"Text_classification.h5\", 5202816)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}